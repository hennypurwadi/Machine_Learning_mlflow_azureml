{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4d50e49",
   "metadata": {},
   "source": [
    "# MLFlow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91bb2717",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/01/15 16:35:37 INFO mlflow.tracking.fluent: Experiment with name 'evaluate_metric' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate_metric (n_estimators=100.000000, max_samples=600.000000):\n",
      "  ACCURACY SCORE: 0.9766666666666667\n",
      "Save to: file:///C:/Users/HENNY/Documents/PYTHON/mlflow_project/mlruns/1/f0085241d45647bc857e46e724046884/artifacts\n",
      "\n",
      "\n",
      "evaluate_metric (n_estimators=110.000000, max_samples=630.000000):\n",
      "  ACCURACY SCORE: 0.9766666666666667\n",
      "Save to: file:///C:/Users/HENNY/Documents/PYTHON/mlflow_project/mlruns/1/e31ddbc4503841aeac3aade558bff921/artifacts\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import csv\n",
    "import json\n",
    "import os\n",
    "import sklearn\n",
    "import mlflow.sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from datetime import datetime\n",
    "from mlflow.tracking import MlflowClient\n",
    "from flask import Flask, flash, request, redirect, url_for\n",
    "from werkzeug.utils import secure_filename\n",
    "\n",
    "mlflow.tracking.get_tracking_uri()\n",
    "exp_name = \"evaluate_metric\"\n",
    "mlflow.set_experiment(exp_name)\n",
    "\n",
    "filedf = \"fraud_detector.csv\"\n",
    "df = pd.read_csv(filedf)  \n",
    "\n",
    "#Ttraining and testing dataset\n",
    "X = df.drop(\"Category\",axis=1)\n",
    "y = df.Category\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3,random_state=40)\n",
    "\n",
    "#Load model\n",
    "model = joblib.load(open(\"model.pkl\", 'rb'))\n",
    "#model= IsolationForest(n_estimators=100, max_samples=len(X_train),random_state=0, verbose=0)   \n",
    "#model.fit(X_train,y_train)\n",
    "\n",
    "ypred= model.predict(X_test)\n",
    "\n",
    "ypred[ypred == 1] = 0 #normal\n",
    "ypred[ypred == -1] = 1 #possibly fraud\n",
    "\n",
    "def eval_metrics(actual, pred):\n",
    "    # compute relevant metrics\n",
    "    acc_score = accuracy_score(y_test,ypred)\n",
    "    return acc_score\n",
    "\n",
    "def load_data(filedf):\n",
    "    df = pd.read_csv(filedf)  \n",
    "    X = df.drop(\"Category\",axis=1)\n",
    "    y = df.Category\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3,random_state=42)\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "def main(n_estimators=40, max_samples=len(X_train)):\n",
    "    # train a model with given parameters\n",
    "    np.random.seed(42)\n",
    "\n",
    "    # Read csv file \n",
    "    filedf = \"fraud_detector.csv\"\n",
    "    train_x, train_y, test_x, test_y = load_data(filedf)\n",
    "\n",
    "    # Useful for multiple runs     \n",
    "    with mlflow.start_run():\n",
    "        # Load model\n",
    "        model = joblib.load(open(\"model.pkl\", 'rb'))\n",
    "                \n",
    "        ypred[ypred == 1] = 0 #normal\n",
    "        ypred[ypred == -1] = 1 #possibly fraud\n",
    "            \n",
    "        #Freeze Model with joblib\n",
    "        filename_pkl = 'model.pkl'\n",
    "        joblib.dump(model, open(filename_pkl, 'wb'))\n",
    "                \n",
    "        # Evaluate Metrics\n",
    "        predicted_qualities = model.predict(X_test)\n",
    "        (acc_score) = eval_metrics(y_test, predicted_qualities)\n",
    "\n",
    "        # Print out metrics\n",
    "        print(\"evaluate_metric (n_estimators=%f, max_samples=%f):\" % (n_estimators, max_samples))\n",
    "        print(\"  ACCURACY SCORE: %s\" % acc_score)\n",
    "       \n",
    "        # Log parameter, metrics, and model to MLflow\n",
    "        mlflow.log_param(key=\"n_estimators\", value=n_estimators)\n",
    "        mlflow.log_param(key=\"max_samples\", value=max_samples)\n",
    "        mlflow.log_metrics({\"accuracy score\":acc_score})\n",
    "        mlflow.log_artifact(filedf)\n",
    "        print(\"Save to: {}\".format(mlflow.get_artifact_uri()))\n",
    "        \n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "     for epoch in range(0, 3):\n",
    "        mlflow.log_metric(key=\"quality\", value=2*epoch, step=epoch)   \n",
    "        \n",
    "main(100,600)\n",
    "print('\\n')\n",
    "main(110,630)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "796b9aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Experiment: artifact_location='file:///C:/Users/HENNY/Documents/PYTHON/mlflow_project/mlruns/0', experiment_id='0', lifecycle_stage='active', name='Default', tags={}>, <Experiment: artifact_location='file:///C:/Users/HENNY/Documents/PYTHON/mlflow_project/mlruns/1', experiment_id='1', lifecycle_stage='active', name='evaluate_metric', tags={}>]\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "experiments = client.list_experiments() # returns a list of mlflow.entities.Experiment\n",
    "print(experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c544a964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Run: data=<RunData: metrics={'accuracy score': 0.9766666666666667}, params={'max_samples': '630', 'n_estimators': '110'}, tags={'mlflow.log-model.history': '[{\"run_id\": \"e31ddbc4503841aeac3aade558bff921\", '\n",
      "                             '\"artifact_path\": \"model\", \"utc_time_created\": '\n",
      "                             '\"2022-01-15 09:35:45.038400\", \"flavors\": '\n",
      "                             '{\"python_function\": {\"model_path\": \"model.pkl\", '\n",
      "                             '\"loader_module\": \"mlflow.sklearn\", '\n",
      "                             '\"python_version\": \"3.8.8\", \"env\": \"conda.yaml\"}, '\n",
      "                             '\"sklearn\": {\"pickled_model\": \"model.pkl\", '\n",
      "                             '\"sklearn_version\": \"0.23.2\", '\n",
      "                             '\"serialization_format\": \"cloudpickle\"}}}]',\n",
      " 'mlflow.source.name': 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py',\n",
      " 'mlflow.source.type': 'LOCAL',\n",
      " 'mlflow.user': 'HENNY'}>, info=<RunInfo: artifact_uri='file:///C:/Users/HENNY/Documents/PYTHON/mlflow_project/mlruns/1/e31ddbc4503841aeac3aade558bff921/artifacts', end_time=1642239349412, experiment_id='1', lifecycle_stage='active', run_id='e31ddbc4503841aeac3aade558bff921', run_uuid='e31ddbc4503841aeac3aade558bff921', start_time=1642239344917, status='FINISHED', user_id='HENNY'>>\n"
     ]
    }
   ],
   "source": [
    "# get the run\n",
    "_run = client.get_run(run_id=\"e31ddbc4503841aeac3aade558bff921\")\n",
    "print(_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73110a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method MlflowClient.set_tag of <mlflow.tracking.client.MlflowClient object at 0x0000026BAC227CA0>>\n",
      "\n",
      "\n",
      "15-01-2022 (16:45:35.943287)\n"
     ]
    }
   ],
   "source": [
    "# add a tag to the run\n",
    "dt = datetime.now().strftime(\"%d-%m-%Y (%H:%M:%S.%f)\")\n",
    "client.set_tag(_run.info.run_id, \"deployed\", dt)\n",
    "print(client.set_tag)\n",
    "print('\\n')\n",
    "print(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa83d6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile main.py\n",
    "\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import csv\n",
    "import json\n",
    "import os\n",
    "import sklearn\n",
    "import mlflow.sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from datetime import datetime\n",
    "from mlflow.tracking import MlflowClient\n",
    "from flask import Flask, flash, request, redirect, url_for\n",
    "from werkzeug.utils import secure_filename\n",
    "\n",
    "exp_name = \"evaluate_metric\"\n",
    "mlflow.set_experiment(exp_name)\n",
    "\n",
    "filedf = \"fraud_detector.csv\"\n",
    "df = pd.read_csv(filedf)  \n",
    "\n",
    "#Ttraining and testing dataset\n",
    "X = df.drop(\"Category\",axis=1)\n",
    "y = df.Category\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3,random_state=40)\n",
    "\n",
    "model = joblib.load(open(\"model.pkl\", 'rb'))\n",
    "#model= IsolationForest(n_estimators=100, max_samples=len(X_train),random_state=0, verbose=0)   \n",
    "#model.fit(X_train,y_train)\n",
    "\n",
    "ypred= model.predict(X_test)\n",
    "\n",
    "ypred[ypred == 1] = 0 #normal\n",
    "ypred[ypred == -1] = 1 #possibly fraud\n",
    "\n",
    "def eval_metrics(actual, pred):\n",
    "    # compute relevant metrics\n",
    "    acc_score = accuracy_score(y_test,ypred)\n",
    "    return acc_score\n",
    "\n",
    "def load_data(filedf):\n",
    "    df = pd.read_csv(filedf)  \n",
    "    X = df.drop(\"Category\",axis=1)\n",
    "    y = df.Category\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3,random_state=42)\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "def main(n_estimators=40, max_samples=len(X_train)):\n",
    "    # train a model with given parameters\n",
    "    np.random.seed(42)\n",
    "\n",
    "    # Read csv file \n",
    "    filedf = \"fraud_detector.csv\"\n",
    "    train_x, train_y, test_x, test_y = load_data(filedf)\n",
    "\n",
    "    # Useful for multiple runs     \n",
    "    with mlflow.start_run():\n",
    "        # Execute \n",
    "        model = joblib.load(open(\"model.pkl\", 'rb'))\n",
    "        #model= IsolationForest(n_estimators=n_estimators, max_samples=max_samples,random_state=0, verbose=0)   \n",
    "        #model.fit(X_train,y_train)\n",
    "        \n",
    "        ypred[ypred == 1] = 0 #normal\n",
    "        ypred[ypred == -1] = 1 #possibly fraud\n",
    "            \n",
    "        #Freeze Model with joblib\n",
    "        filename_pkl = 'model.pkl'\n",
    "        joblib.dump(model, open(filename_pkl, 'wb'))\n",
    "        print(\"model.pkl saved\")\n",
    "        \n",
    "        # Evaluate Metrics\n",
    "        predicted_qualities = model.predict(X_test)\n",
    "        (acc_score) = eval_metrics(y_test, predicted_qualities)\n",
    "\n",
    "        # Print out metrics\n",
    "        print(\"evaluate_metric (n_estimators=%f, max_samples=%f):\" % (n_estimators, max_samples))\n",
    "        print(\"  ACCURACY SCORE: %s\" % acc_score)\n",
    "       \n",
    "        # Log parameter, metrics, and model to MLflow\n",
    "        mlflow.log_param(key=\"n_estimators\", value=n_estimators)\n",
    "        mlflow.log_param(key=\"max_samples\", value=max_samples)\n",
    "        mlflow.log_metrics({\"accuracy score\":acc_score})\n",
    "        mlflow.log_artifact(filedf)\n",
    "        print(\"Save to: {}\".format(mlflow.get_artifact_uri()))\n",
    "        \n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "     for epoch in range(0, 3):\n",
    "        mlflow.log_metric(key=\"quality\", value=2*epoch, step=epoch)        \n",
    "        \n",
    "main(107, 680)\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "#    mlflow ui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18352810",
   "metadata": {},
   "source": [
    "# Automate scheduled training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a783fbc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing trigger_train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile trigger_train.py\n",
    "\n",
    "def trigger_train(): \n",
    "   \n",
    "    import sklearn\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import pandas as pd\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import classification_report,accuracy_score\n",
    "    from sklearn.ensemble import IsolationForest\n",
    "    import joblib\n",
    "    import datetime\n",
    "    import requests\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "       \n",
    "    filedf = 'fraud_detector.csv'\n",
    "    df= pd.read_csv(filedf)\n",
    "    X = df.drop(\"Category\",axis=1)\n",
    "    y = df.Category\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3,random_state=40)\n",
    "\n",
    "    model= IsolationForest(n_estimators=100, max_samples=len(X_train),random_state=0, verbose=0)   \n",
    "    model.fit(X_train,y_train)\n",
    "    #model = joblib.load(open(\"model.pkl\", 'rb'))\n",
    "   \n",
    "    ypred= model.predict(X_test)\n",
    "    ypred[ypred == 1] = 0 #normal\n",
    "    ypred[ypred == -1] = 1 #possibly fraud \n",
    "    \n",
    "    #Freeze Model with joblib\n",
    "    filename_pkl = 'model.pkl'\n",
    "    joblib.dump(model, open(filename_pkl, 'wb'))\n",
    "    print(\"model.pkl saved\")\n",
    "    \n",
    "#Automate scheduled training    \n",
    "#mlflow.autolog({\"run_id\":\"749eb2eaf2a84e1992110481c7a7a7a9\"})  \n",
    "trigger_train()\n",
    "\n",
    "import schedule\n",
    "schedule.every(720).hours.do(trigger_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f1c0f6",
   "metadata": {},
   "source": [
    "#### From terminal type \n",
    "(base) PS C:\\Users\\HENNY\\Documents\\PYTHON\\mlflow_project> mlflow ui\n",
    "\n",
    "(envi1) (base) PS C:\\Users\\HENNY\\Documents\\PYTHON\\mlflow_project> mlflow ui\n",
    "INFO:waitress:Serving on http://127.0.0.1:5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0fab75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#schedule.every(720).hours.do(trigger_train)  \n",
    "#schedule.every(10).seconds.do(trigger_train)\n",
    "#schedule.every(15).minutes.do(trigger_train)\n",
    "#schedule.every().day.at('09:01').do(trigger_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9536377b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c305151",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "163f573e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "\n",
    "import sklearn\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from flask import Flask, flash, request, redirect, url_for\n",
    "from werkzeug.utils import secure_filename\n",
    "import json\n",
    "import joblib\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route(\"/status\")\n",
    "def status():\n",
    "    return \"success\"\n",
    "\n",
    "@app.route(\"/\", methods=['GET', 'POST'])\n",
    "def index():\n",
    "    A1 = request.args.get(\"A1\", None)\n",
    "    A2 = request.args.get(\"A2\", None)\n",
    "\n",
    "    #request_value = request.get_json()\n",
    "\n",
    "    #A1 = int(request_value[\"A1\"])\n",
    "    #A2 = int(request_value[\"A2\"])\n",
    "\n",
    "    if A1 != None:\n",
    "        y_new = predict(A1, A2)\n",
    "    else:\n",
    "        y_new = \"\"\n",
    "\n",
    "    write(A1, A2, y_new)\n",
    "    return (\n",
    "        \"\"\"<form action=\"\" method=\"get\">\n",
    "                A1 input: <input type=\"text\" name=\"A1\">\n",
    "                A2 input: <input type=\"text\" name=\"A2\">\n",
    "                <input type=\"submit\" value=\"A1 & A2 input for Predict Fraud or Not\">\n",
    "            </form>\"\"\"\n",
    "\n",
    "        + \"y_new: \"\n",
    "        + str(y_new)\n",
    "    )\n",
    "\n",
    "@app.route(\"/json\", methods=['GET', 'POST'])\n",
    "def jsonify():\n",
    "    request_value = request.get_json()\n",
    "    return request_value\n",
    "\n",
    "def write(A1, A2, y_new):\n",
    "    filedf = \"fraud_detector.csv\"\n",
    "    # write new data into csv\n",
    "    with open(filedf, 'a', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([A1, A2, y_new])\n",
    "        print(\"file written\")\n",
    "\n",
    "def predict(A1, A2):\n",
    "    \"\"\"Predict Fraud or Not Fraud.\"\"\"\n",
    "    print(\"predicting\")\n",
    "\n",
    "    model = joblib.load(open(\"model.pkl\", 'rb'))\n",
    "    X_new = np.array([A1, A2]).reshape(1, -1)\n",
    "    y_new = model.predict(X_new)\n",
    "\n",
    "    y_new[y_new == 1] = 0  # normal\n",
    "    y_new[y_new == -1] = 1  # possibly fraud\n",
    "\n",
    "    y_new = (int(y_new))\n",
    "    return y_new\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host=\"0.0.0.0\", port=int(\"5000\"), debug=True, use_reloader=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8952475",
   "metadata": {},
   "source": [
    "#### Create image and Docker Container  \n",
    "(base) PS C:\\Users\\HENNY\\Documents\\PYTHON\\mlflow_project> pip install --user virtualenv\n",
    "\n",
    "(base) PS C:\\Users\\HENNY\\Documents\\PYTHON\\mlflow_project> python -m venv envi1\n",
    "\n",
    "(base) PS C:\\Users\\HENNY\\Documents\\PYTHON\\mlflow_project>.\\envi1\\Scripts\\activate\n",
    "\n",
    "(envi1)(base) PS C:\\Users\\HENNY\\Documents\\PYTHON\\mlflow_project> pip install -r requirements.txt\n",
    "\n",
    "(envi1)(base) PS C:\\Users\\HENNY\\Documents\\PYTHON\\mlflow_project> docker build -t image01 .\n",
    "\n",
    "(envi1)(base) PS C:\\Users\\HENNY\\Documents\\PYTHON\\mlflow_project> docker run --name container01 -p 5000:5000 image01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d207f70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
